{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bd0e597-8523-4e40-a7de-167e40d3e539",
   "metadata": {},
   "source": [
    "# FAA Maintenance Log Classification with BERT\n",
    "\n",
    "This project builds a **text classification pipeline** for FAA Service Difficulty Reports (SDR) using **BERT fine-tuning**.\n",
    "\n",
    "## Goal\n",
    "Classify free-text **Discrepancy** narratives into high-level aircraft system categories (e.g., STRUCTURES, AVIONICS/ELECTRICAL, POWERPLANT).  \n",
    "This enables automated triage and trend analysis of maintenance issues\n",
    ".\n",
    "To achieve this, we demonstrate:\n",
    "- **Data wrangling & cleaning**: parsing raw FAA SDR `.xls` HTML tables into a consistent dataset.  \n",
    "- **Category engineering**: mapping fine-grained JASC codes into ~7–8 balanced categories.  \n",
    "- **Fine-tuning BERT**: adapting a pretrained model (DistilBERT / BERT-base) for aerospace maintenance text.  \n",
    "- **Few-shot inference**: testing model predictions on novel, hand-crafted examples to evaluate generalization.  \n",
    "- **Class imbalance handling**: merging sparse categories, experimenting with weighted loss.  \n",
    "- **Evaluation & analysis**: reporting macro-F1, confusion matrices, and error case studies.  \n",
    "- **Reusable inference interface**: providing a lightweight CLI script to classify new log entries.\n",
    "\n",
    "## Why BERT?\n",
    "- **Domain-specific challenge**: Maintenance logs are short, technical, and use aviation-specific terminology.  \n",
    "- **Limitations of traditional models**: TF-IDF + Logistic Regression baselines often fail to capture context or rare phrases.  \n",
    "- **BERT advantage**: Pretrained on large corpora, BERT can capture contextual meaning (e.g., “wing crack” vs “engine crack”) and generalize better to unseen phrasing.\n",
    "\n",
    "## Data \n",
    "(See previous EDA notebook for more deatail of how labels are grouped based on their JASC code)\n",
    "- Source: FAA Service Difficulty Reports (SDR), Boeing 767 (2022–2025).  \n",
    "- After cleaning and mapping JASC codes → Categories, dataset size is ~14k rows.  \n",
    "- Categories were **consolidated into 7 balanced groups** to avoid data sparsity:\n",
    "  - STRUCTURES  \n",
    "  - AVIONICS/ELECTRICAL  \n",
    "  - POWERPLANT  \n",
    "  - CABIN  \n",
    "  - FLUID_SYSTEMS  \n",
    "  - ENVIRONMENTAL/SAFETY  \n",
    "  - FLIGHT_CONTROLS\n",
    "\n",
    "## Pipeline\n",
    "1. **Data acquisition & merge**: Parse FAA SDR HTML `.xls` exports into one combined CSV.  \n",
    "2. **EDA & Cleaning**: Normalize dates, remove blanks, analyze text length & class balance.  \n",
    "3. **Category Mapping**: Convert JASC codes → domain-relevant system categories, merge rare labels.  \n",
    "4. **Train/Val/Test Split**: Stratified to preserve class distribution.  \n",
    "5. **Modeling**: Fine-tune `distilbert-base-uncased` (later `bert-base-uncased`).  \n",
    "6. **Evaluation**: Macro-F1, confusion matrix, per-class reports.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af977579-098c-45a6-a2ce-e62c2760fa9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import and data\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../data/processed/sdr_training.csv\")\n",
    "OUTPUT_DIR = \"../outputs/bert\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85d469b7-ec91-4a19-be83-3201e29995b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 10,026 | Val: 2,149 | Test: 2,149\n",
      "\n",
      "Class distribution (proportions):\n",
      "Full:\n",
      " Category_adj\n",
      "AVIONICS/ELECTRICAL     0.158\n",
      "CABIN                   0.046\n",
      "ENVIRONMENTAL/SAFETY    0.046\n",
      "FLIGHT_CONTROLS         0.027\n",
      "FLUID_SYSTEMS           0.042\n",
      "POWERPLANT              0.065\n",
      "STRUCTURES              0.617\n",
      "Name: proportion, dtype: float64\n",
      "Train:\n",
      " Category_adj\n",
      "AVIONICS/ELECTRICAL     0.158\n",
      "CABIN                   0.046\n",
      "ENVIRONMENTAL/SAFETY    0.046\n",
      "FLIGHT_CONTROLS         0.027\n",
      "FLUID_SYSTEMS           0.042\n",
      "POWERPLANT              0.065\n",
      "STRUCTURES              0.617\n",
      "Name: proportion, dtype: float64\n",
      "Val:\n",
      " Category_adj\n",
      "AVIONICS/ELECTRICAL     0.158\n",
      "CABIN                   0.047\n",
      "ENVIRONMENTAL/SAFETY    0.046\n",
      "FLIGHT_CONTROLS         0.027\n",
      "FLUID_SYSTEMS           0.042\n",
      "POWERPLANT              0.065\n",
      "STRUCTURES              0.617\n",
      "Name: proportion, dtype: float64\n",
      "Test:\n",
      " Category_adj\n",
      "AVIONICS/ELECTRICAL     0.158\n",
      "CABIN                   0.047\n",
      "ENVIRONMENTAL/SAFETY    0.046\n",
      "FLIGHT_CONTROLS         0.027\n",
      "FLUID_SYSTEMS           0.041\n",
      "POWERPLANT              0.064\n",
      "STRUCTURES              0.617\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Splitng data set \n",
    "X = df[\"Discrepancy\"].astype(str)\n",
    "y = df[\"Category_adj\"]\n",
    "#We spliting the data set into training and testing with the same probotion as original data \n",
    "SEED = 676\n",
    "\n",
    "X_train, X_tmp, y_train, y_tmp = train_test_split(\n",
    "    X, y, test_size=0.30, stratify=y, random_state=SEED\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_tmp, y_tmp, test_size=0.50, stratify=y_tmp, random_state=SEED\n",
    ")\n",
    "\n",
    "print(f\"Train: {len(X_train):,} | Val: {len(X_val):,} | Test: {len(X_test):,}\")\n",
    "\n",
    "# quick distribution check\n",
    "def dist(s): \n",
    "    return s.value_counts(normalize=True).sort_index().round(3)\n",
    "\n",
    "print(\"\\nClass distribution (proportions):\")\n",
    "print(\"Full:\\n\", dist(y))\n",
    "print(\"Train:\\n\", dist(y_train))\n",
    "print(\"Val:\\n\", dist(y_val))\n",
    "print(\"Test:\\n\", dist(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f41b774e-b1e0-4843-9baa-a736eecc8fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['AVIONICS/ELECTRICAL', 'CABIN', 'ENVIRONMENTAL/SAFETY', 'FLIGHT_CONTROLS', 'FLUID_SYSTEMS', 'POWERPLANT', 'STRUCTURES']\n",
      "num_labels: 7\n"
     ]
    }
   ],
   "source": [
    "#Label encoding \n",
    "#  Models can’t work with text labels  so We convert our labels from text to integer. \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder().fit(y_train)\n",
    "y_train_id = le.transform(y_train)\n",
    "y_val_id   = le.transform(y_val)\n",
    "y_test_id  = le.transform(y_test)\n",
    "\n",
    "num_labels = len(le.classes_)\n",
    "id2label = {i: c for i, c in enumerate(le.classes_)}\n",
    "label2id = {c: i for i, c in id2label.items()}\n",
    "\n",
    "print(\"Classes:\", list(le.classes_))\n",
    "print(\"num_labels:\", num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f803962b-e85d-4523-966c-92118347cc00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10026, 2149, 2149)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build HF datasets\n",
    "from datasets import Dataset\n",
    "\n",
    "train_df = pd.DataFrame({\"text\": X_train.tolist(), \"labels\": y_train_id})\n",
    "val_df   = pd.DataFrame({\"text\": X_val.tolist(),   \"labels\": y_val_id})\n",
    "test_df  = pd.DataFrame({\"text\": X_test.tolist(),  \"labels\": y_test_id})\n",
    "\n",
    "ds_train = Dataset.from_pandas(train_df, preserve_index=False)\n",
    "ds_val   = Dataset.from_pandas(val_df,   preserve_index=False)\n",
    "ds_test  = Dataset.from_pandas(test_df,  preserve_index=False)\n",
    "\n",
    "len(ds_train), len(ds_val), len(ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01d5b6ed-1acb-4e61-9105-c2f71cc6964b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys, platform\n",
    "#print(sys.executable)   # should point to ...\\anaconda3\\envs\\ds-interview\\python.exe\n",
    "#print(platform.python_version())\n",
    "#%pip install --upgrade --index-url https://download.pytorch.org/whl/cpu torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afba39f6-db2d-4ad2-8b63-7423eac8bb50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Requirement already satisfied: torch in c:\\users\\dcuon\\anaconda3\\envs\\ds-interview\\lib\\site-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: torchvision in c:\\users\\dcuon\\anaconda3\\envs\\ds-interview\\lib\\site-packages (0.20.1+cu121)\n",
      "Requirement already satisfied: filelock in c:\\users\\dcuon\\anaconda3\\envs\\ds-interview\\lib\\site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\dcuon\\anaconda3\\envs\\ds-interview\\lib\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\dcuon\\anaconda3\\envs\\ds-interview\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dcuon\\anaconda3\\envs\\ds-interview\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\dcuon\\anaconda3\\envs\\ds-interview\\lib\\site-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\dcuon\\anaconda3\\envs\\ds-interview\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\dcuon\\anaconda3\\envs\\ds-interview\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\dcuon\\anaconda3\\envs\\ds-interview\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\dcuon\\anaconda3\\envs\\ds-interview\\lib\\site-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dcuon\\anaconda3\\envs\\ds-interview\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#Run this if you need py torch, or if there is conflict in enviroment only\n",
    "%pip install --upgrade --index-url https://download.pytorch.org/whl/cu121 torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a684f63-aa2c-440a-996f-535ec4c7ee86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba6b7ba37440408b9ecaa43c9ec6556a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10026 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10786fc186dd4c63b9c660268be69c9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2149 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f220e0e767b24cf6b24adf512516d190",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2149 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['labels', 'input_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [5] Tokenizer\n",
    "# ---------------------------\n",
    "# Why?\n",
    "# - Transformers like BERT cannot read raw text, they need token IDs.\n",
    "# -  We can use Hugging Face AutoTokenizer loads to get the tokkens ID.\n",
    "# - Each sentence will be:\n",
    "#     * Split into subword tokens (WordPiece)\n",
    "#     * Mapped to IDs from the pretrained vocab\n",
    "#     * Truncated or padded to a fixed length\n",
    "# - After this step, our Hugging Face Dataset will contain fields like:\n",
    "#     input_ids, attention_mask, labels\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "#Config\n",
    "MODEL_NAME = \"distilbert-base-uncased\"\n",
    "MAX_LEN = 128\n",
    "\n",
    "# Load tokenizer tied to DistilBERT\n",
    "tok = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "# Function to apply tokenizer to a batch of examples\n",
    "def tok_fn(batch):\n",
    "    return tok(\n",
    "        batch[\"text\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=MAX_LEN,\n",
    "    )\n",
    "    \n",
    "# Apply tokenizer to train/val/test datasets\n",
    "# remove_columns=[\"text\"] since we don’t need raw text inside model input\n",
    "ds_train_tok = ds_train.map(tok_fn, batched=True, remove_columns=[\"text\"])\n",
    "ds_val_tok   = ds_val.map(tok_fn, batched=True, remove_columns=[\"text\"])\n",
    "ds_test_tok  = ds_test.map(tok_fn, batched=True, remove_columns=[\"text\"])\n",
    "# Convert Hugging Face dataset into PyTorch tensors (for Trainer)\n",
    "ds_train_tok.set_format(\"torch\")\n",
    "ds_val_tok.set_format(\"torch\")\n",
    "ds_test_tok.set_format(\"torch\")\n",
    "\n",
    "ds_train_tok[0].keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5c2076a-1693-4d62-99bd-4a497807a578",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# [6] Model setup\n",
    "# - We load a pretrained DistilBERT model for sequence classification.\n",
    "# - The classification head is configured with our number of labels.\n",
    "# - We also handle class imbalance by computing weights for each class.\n",
    "     \n",
    "import numpy as np, torch, torch.nn as nn\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "# Configure if we will use class weights. In this case we use class weights as our classes are not balanced\n",
    "################################################################################\n",
    "use_class_weights = True  # flip to False if we don;t want to use class weights\n",
    "#################################################################################\n",
    "# Load DistilBERT with a classification head\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=num_labels,   #number of category\n",
    "    id2label=id2label,       # int -> class name mapping\n",
    "    label2id=label2id,       # class name -> int mapping\n",
    ")\n",
    "\n",
    "if use_class_weights:\n",
    "    counts = np.bincount(y_train_id, minlength=num_labels) # samples per class\n",
    "    weights = counts.sum() / (counts + 1e-9)      # # inverse frequency weighting\n",
    "    weights = weights / weights.mean() # normalize\n",
    "    class_weights_t = torch.tensor(weights, dtype=torch.float)\n",
    "    \n",
    "# These weights will be plugged into CrossEntropyLoss later in Trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e2a8527-f60f-47b1-84fe-390f1f5d3900",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import transformers, inspect, sys\n",
    "#print(\"transformers version:\", transformers.__version__)\n",
    "#print(\"loaded from:\", transformers.__file__)\n",
    "#from transformers import TrainingArguments\n",
    "#print(\"TrainingArguments signature:\\n\", inspect.signature(TrainingArguments.__init__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f300aab-d38c-4857-9073-a79381d9c072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [7] TrainingArguments + Trainer (Transformers 4.56+)\n",
    "#  Configure for hyperparameter and training arguments\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import numpy as np\n",
    "import torch, torch.nn as nn\n",
    "\n",
    "\n",
    "# Function: compute metrics after each eval step\n",
    "# We report both accuracy and macro-F1 (balances across classes)\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "    return {\n",
    "        \"acc\": accuracy_score(labels, preds),\n",
    "        \"f1_macro\": f1_score(labels, preds, average=\"macro\"),\n",
    "    }\n",
    "\n",
    "# Hyperparameter config\n",
    "EPOCHS = 3\n",
    "LR = 2e-5\n",
    "BATCH_TRAIN = 16\n",
    "BATCH_EVAL = 32\n",
    "FP16 = torch.cuda.is_available() # use mixed precision if GPU available\n",
    "\n",
    "# TrainingArguments control the Trainer's behavior\n",
    "args_tr = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_TRAIN,\n",
    "    per_device_eval_batch_size=BATCH_EVAL,\n",
    "    learning_rate=LR,\n",
    "    weight_decay=0.01,            # L2 regularization\n",
    "    eval_strategy=\"steps\",        # evaluate every N steps\n",
    "    save_strategy=\"steps\",        # save checkpoint every N steps\n",
    "    logging_steps=50,\n",
    "    eval_steps=300,               # run eval every 300 steps\n",
    "    save_steps=300,               # restore best checkpoint (based on metric_for_best_model)\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1_macro\",\n",
    "    fp16=FP16,                     # use FP16 for faster training on GPU\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "# ---- Weighted trainer -\n",
    "class WeightedTrainer(Trainer):\n",
    "    def __init__(self, class_weights=None, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.class_weights = class_weights \n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        outputs = model(**inputs)\n",
    "        logits  = outputs.get(\"logits\")\n",
    "        labels  = inputs.get(\"labels\")\n",
    "\n",
    "        if labels is not None and logits is not None:\n",
    "            if self.class_weights is not None:\n",
    "                loss_fct = nn.CrossEntropyLoss(weight=self.class_weights.to(logits.device))\n",
    "            else:\n",
    "                loss_fct = nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(logits, labels)\n",
    "        else:\n",
    "            loss = outputs.get(\"loss\")\n",
    "\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "# ---- Instantiate trainer (use processing_class instead of deprecated tokenizer) ----\n",
    "if use_class_weights:\n",
    "    trainer = WeightedTrainer(\n",
    "        model=model,\n",
    "        args=args_tr,\n",
    "        train_dataset=ds_train_tok,\n",
    "        eval_dataset=ds_val_tok,\n",
    "        processing_class=tok,         \n",
    "        compute_metrics=compute_metrics,\n",
    "        class_weights=class_weights_t,\n",
    "    )\n",
    "else:\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=args_tr,\n",
    "        train_dataset=ds_train_tok,\n",
    "        eval_dataset=ds_val_tok,\n",
    "        processing_class=tok,          \n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0cf63c59-385c-486c-ac7d-f50c7def14b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1881' max='1881' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1881/1881 02:18, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Acc</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.886100</td>\n",
       "      <td>0.719475</td>\n",
       "      <td>0.794323</td>\n",
       "      <td>0.685859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.473500</td>\n",
       "      <td>0.485246</td>\n",
       "      <td>0.867380</td>\n",
       "      <td>0.772676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.400300</td>\n",
       "      <td>0.500465</td>\n",
       "      <td>0.901815</td>\n",
       "      <td>0.827178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.480800</td>\n",
       "      <td>0.488800</td>\n",
       "      <td>0.913913</td>\n",
       "      <td>0.840139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.300900</td>\n",
       "      <td>0.472811</td>\n",
       "      <td>0.909260</td>\n",
       "      <td>0.831906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.287800</td>\n",
       "      <td>0.451557</td>\n",
       "      <td>0.902280</td>\n",
       "      <td>0.825684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1881, training_loss=0.5631307797632212, metrics={'train_runtime': 139.52, 'train_samples_per_second': 215.582, 'train_steps_per_second': 13.482, 'total_flos': 996177423324672.0, 'train_loss': 0.5631307797632212, 'epoch': 3.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [8] Train\n",
    "train_output = trainer.train()\n",
    "train_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "537935e6-5e90-4976-8958-d8ab009497d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST metrics: {'eval_loss': 0.5481747984886169, 'eval_acc': 0.9060027919962773, 'eval_f1_macro': 0.823120792426267, 'eval_runtime': 1.4518, 'eval_samples_per_second': 1480.258, 'eval_steps_per_second': 46.839, 'epoch': 3.0}\n",
      "\n",
      "TEST classification report:\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      " AVIONICS/ELECTRICAL      0.896     0.894     0.895       339\n",
      "               CABIN      0.710     0.710     0.710       100\n",
      "ENVIRONMENTAL/SAFETY      0.879     0.879     0.879        99\n",
      "     FLIGHT_CONTROLS      0.702     0.690     0.696        58\n",
      "       FLUID_SYSTEMS      0.703     0.933     0.802        89\n",
      "          POWERPLANT      0.832     0.826     0.829       138\n",
      "          STRUCTURES      0.961     0.942     0.951      1326\n",
      "\n",
      "            accuracy                          0.906      2149\n",
      "           macro avg      0.812     0.839     0.823      2149\n",
      "        weighted avg      0.909     0.906     0.907      2149\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# [9] Test evaluation + classification report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Aggregate metrics on TEST (uses the HF eval loop)\n",
    "test_metrics = trainer.evaluate(ds_test_tok)\n",
    "print(\"TEST metrics:\", test_metrics)\n",
    "# Per-class metrics: get raw predictions, argmax to class IDs\n",
    "pred_logits = trainer.predict(ds_test_tok).predictions\n",
    "pred_ids = np.argmax(pred_logits, axis=1)\n",
    "\n",
    "print(\"\\nTEST classification report:\\n\",\n",
    "      classification_report(y_test_id, pred_ids, target_names=list(le.classes_), digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00eeff4f-3cbe-4db4-bdc1-936cfd94f4f0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33d718e5-bf1c-4826-b1c7-8fad0443fe7a",
   "metadata": {},
   "source": [
    "~90% of test examples classified correctly iwth Macro F1 ~ 81.73\n",
    "\n",
    "Main take away:\n",
    " - The model does very well on the dominant classes like AVIONICS/ ELECTRICAL, STRUCTURES, etc..\n",
    " - Macro-F1 < accuracy indicates some smaller classes perform worse\n",
    " - Cabin has weak precision but reasoanble recall suggest that the model over predict cabin in borderline case\n",
    " -  (57% of what model predict as cabin is actually cabin), (Of all cabin, model can identify 74% cabins)\n",
    "\n",
    "Things to inspect and consider for improvement:\n",
    " - Inspect confusion: build a confusion matrix to see which classes are confused with CABIN.\n",
    " - Try larger Max_length if narratives are being truncated\n",
    " - Hyperparams: small LR sweep (1e-5–5e-5), epochs=3–5, adjust eval_steps\n",
    " - Model: try roberta-base (often stronger on classification) with same pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37b465f3-d226-49b5-a957-3d7beec2462b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: ..\\outputs\\bert\\best_model\n"
     ]
    }
   ],
   "source": [
    "# [10] Save best model + tokenizer + label classes\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "best_dir = Path(OUTPUT_DIR) / \"best_model\"\n",
    "best_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "trainer.save_model(str(best_dir))\n",
    "tok.save_pretrained(str(best_dir))\n",
    "\n",
    "with open(best_dir / \"label_classes.json\", \"w\") as f:\n",
    "    json.dump(list(le.classes_), f, indent=2)\n",
    "\n",
    "(best_dir / \"id2label.json\").write_text(json.dumps(id2label, indent=2))\n",
    "(best_dir / \"label2id.json\").write_text(json.dumps(label2id, indent=2))\n",
    "\n",
    "print(\"Saved to:\", best_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "379befc0-444f-4bc9-af05-2bef6672fb46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FLUID_SYSTEMS']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [11] Inference helper\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "loaded_tok = AutoTokenizer.from_pretrained(best_dir)\n",
    "loaded_model = AutoModelForSequenceClassification.from_pretrained(best_dir).to(device)\n",
    "\n",
    "def predict_category(texts):\n",
    "    if isinstance(texts, str):\n",
    "        texts = [texts]\n",
    "    enc = loaded_tok(texts, padding=True, truncation=True, max_length=MAX_LEN, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = loaded_model(**enc).logits\n",
    "    pred_ids = logits.argmax(dim=1).cpu().numpy().tolist()\n",
    "    return [id2label[i] for i in pred_ids]\n",
    "\n",
    "# try it:\n",
    "predict_category(\"FUEL PRESSURE LOW LIGHT ON DURING CLIMB; CHECKED LINES AND REPLACED PUMP.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e90831-309f-4c4c-a7a9-ae68ea837b4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6dd174d-0235-4f7c-ad70-c0eabc20d88b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae8e644-7d48-4ddd-beea-75170a918a61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
